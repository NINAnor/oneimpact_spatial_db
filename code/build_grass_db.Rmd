---
title: "Build GRASS GIS database"
author: ""
date: "`r format(Sys.time(), '%d %B, %Y')`"
geometry: margin=2cm
output: 
  NinaR::jensAnalysis:
    highlight: tango
    fig_caption: yes
    toc: yes
---


```{r load_packages, message = F, warning = F}
# Load packages
require(dplyr)
require(purrr)
require(readr)
require(NinaR)

require(rgrass7)
require(sp)
require(raster)
require(terra)
require(rgdal)
require(sf)

source("functions.R")
```

```{r setup, include=FALSE}
# This is optional
# I choose the 'styler' package for tidying the code to preserve indentations
# I set the cutoff for code tidying to 60, but this doesn't currently work with styler.
# Set tidy = True to get the knitr default
# I want all figures as png and pdf in high quality in a subfolder called figure

knitr::opts_chunk$set(
  eval = FALSE, # do not run anything
  echo = TRUE,
  tidy = "styler",
  dev = c("png", "pdf"),
  dpi = 600,
  fig.path = "figure/"
)

options(
  xtable.comment = F,
  xtable.include.rownames = F,
  nina.logo.y.pos = 0.15
)
palette(ninaPalette())
```

# Connect to GRASS GIS

We start by connecting the R session to GRASS GIS, in my local user mapset (`u_bernardo.brandao`).

```{r connectGRASS}
# Connect to GRASS
NinaR::grassConnect(location = "ETRS_33N", mapset = "user")

# example of command
#execGRASS("g.mapset", parameters = list(), flags = )
```


# Get read access to the existing mapsets

```{r}
# list all mapsets
sep <- " "
all_mapsets <- execGRASS("g.mapsets", flags = c("l"), intern = T) %>% 
  strsplit(sep) %>% 
  first()

# list mapsets for "rein"
mapset_patt_rein <- c("Rein", "rein") %>% 
  paste(collapse = "|")
mapsets_rein <- all_mapsets %>% 
  grep(pattern = mapset_patt_rein, value = T)

# list mapsets for "Prodchange"
mapset_patt_pc <- c("change") %>% 
  paste(collapse = "|")
mapsets_pc <- all_mapsets %>% 
  grep(pattern = mapset_patt_pc, value = T) %>% 
  grep(pattern = paste(mapsets_rein,collapse = "|"), invert = T, value = T)

# list some more mapsets we know we'll use
land_use_mapsets <- c("p_RenRein_norut", "g_LandCover_Norway_NORUT_SAM_TT", 
                      "p_prodchange_envpolyTT")
landscape_mapsets <- c("g_Elevation_Fenoscandia", "g_LandCover_Fenoscndia_PHENOLOGY_SAM_TT", 
                       "g_Elevation_Fenoscandia_TPI")
climate_mapsets <- c("g_BiogeographicalRegions_Norway_PCA_klima", "u_bram.van.moorter",
                     "g_EnergyResources_Fenoscandia", "u_torkildtveraa")
infrastructure_mapsets <- c("p_prodchange_envpointsTT", "p_prodchange_roadsTT", "p_RenRein_trails2", 
                            "p_prodchange_trailsTT")

all_relevant_mapsets <- c(mapsets_rein, mapsets_pc, 
                          land_use_mapsets, landscape_mapsets, 
                          climate_mapsets, infrastructure_mapsets) %>% 
  unique()

# access to those mapsets
execGRASS("g.mapsets", parameters = list(mapset = all_relevant_mapsets))
```


# Create new mapsets

Let's create the new mapsets here. There are six mapsets:

- `climate_phenology`
- `landscape`
- `species`
- `industr`
- `transport_urban`
- `urban`

Describe the idea of each one here.

```{r create_mapsets}
# Create mapsets
mapsets <- c("climate_phenology", "landscape", "species", 
             "industry", "transport_urban", "tourism")
mapsets <- paste0("p_sam_", mapsets)

for(ms in mapsets) {
  execGRASS("g.mapset", parameters = list(mapset = ms), flags = "c")
}
```

# Load data

Before starting to load data, we define here some paths to the folders where the datasets are located. 
If it is necessary, one can simply change the path and re-load the data.

```{r paths}
# Define paths

# root folder Sweden
sw_dir = "/data/P-Prosjekter/41203800_oneimpact/sam_raw_sw/"
```


# Load landscape data

## Data from Norway

Here we'll copy the datasets from Norway that have already been in use in the previous projects (e.g. Renewable Reindeer, Prodchange).

### Land use - NORUT

```{r copy_landscape_NORUT}
# go into mapset
ms <- "p_sam_landscape"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "landscape"

#---
# land use
ms_from <- "p_RenRein_norut"
maps <- execGRASS("g.list", type = "raster", mapset = ms_from, intern = T)

# copy
for(i in maps) {
  map_in <- paste0(i, "@", ms_from)
  map_out <- i
  execGRASS("g.region", raster = map_in)
  execGRASS("g.copy", raster=paste0(map_in, ",", map_out), flags = c("overwrite"))
}

# document
md_file <- list.files("../data/", pattern = "spatialdb_metadata_oneimpact", full.names = T)
md <- readr::read_csv(md_file)

# maps used or not used earlier
used <- grep("100", maps, value = T)
not_used <- setdiff(maps, used)
used_names <- c("agricultural lands", "glacier", "grasses", "heather in lowland", "heather in ridges",
                "heathlands", "forest with lichens", "lichens", "meadows", "mires", "ridges", "forest",
                "snow", "snowbed")
used_names <- paste0("Land cover: ", c(used_names))
not_used_names <- used_names

# used maps
md_updated <- update_metadata(md, 
                              maps = used, 
                              type_of_info = type_of_info,
                              mapset_from = ms_from, 
                              new_mapset = ms, 
                              variables = used_names, 
                              institution = NA,
                              description = NA, 
                              unit = NA, 
                              type_data = "raster",
                              original_range_values = "0, 1", 
                              year_data = NA,
                              original_pixel_res = 30, #???
                              final_pixel_res = 30, 
                              extent = "Norway",
                              primary_derived = "Primary",
                              derived_form = NA,
                              website = NA, 
                              source = NA, 
                              obtained_through = "NINA", 
                              observations = NA)
md_updated

# maps unused earlier
md_updated <- update_metadata(md_updated, 
                              maps = not_used, 
                              type_of_info = type_of_info,
                              mapset_from = ms_from, 
                              new_mapset = ms, 
                              variables = not_used_names, 
                              institution = NA,
                              description = NA, 
                              unit = NA, 
                              type_data = "raster",
                              original_range_values = "0, 1", 
                              year_data = NA,
                              original_pixel_res = 30, #??
                              final_pixel_res = 100, 
                              extent = "Norway",
                              primary_derived = "Resampled",
                              derived_form = "NORUT land use classes",
                              website = NA, 
                              source = NA, 
                              obtained_through = "NINA", 
                              observations = NA)
md_updated

# write updated metadata on the disk
readr::write_csv(md_updated, file = paste0("../data/spatialdb_metadata_oneimpact_",
                                           gsub("-", "", lubridate::today()),
                                           ".csv"))
# put the old metadata file in archive
# system(paste("mv", md_file, "../data/old_metadata"))

#---
# land use density
# This data is present in the mapset "g_LandCover_Norway_NORUT_SAM_TT", 
# but it should be recalculated
# with the data from Sweden
# But we need to compare the land use maps first
```

### Elevation for Fennoscandia

```{r copy_landscape_elevation}
# go into mapset
ms <- "p_sam_landscape"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "landscape"

#---
# elevation, slope, aspect???
```

### TPI for Fennoscandia

```{r copy_landscape_TPI}
# go into mapset
ms <- "p_sam_landscape"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "landscape"

#---
# TPI - 50m
ms_from <- "g_Elevation_Fenoscandia_TPI"
maps <- execGRASS("g.list", type = "raster", mapset = ms_from, intern = T)

# copy
for(i in maps) {
  map_in <- paste0(i, "@", ms_from)
  map_out <- i
  execGRASS("g.region", raster = map_in)
  execGRASS("g.copy", raster=paste0(map_in, ",", map_out), flags = c("overwrite"))
}

# document
md_file <- list.files("../data/", pattern = "spatialdb_metadata_oneimpact", full.names = T)
md <- readr::read_csv(md_file)

maps
scales <- purrr::map_chr(strsplit(maps, "_"), ~.[3])
map_names <- paste0("Terrain Position Index: ", scales, "m")

# get min and max from GRASS maps
min_max <- get_univar(maps, vars = c("min", "max"), all_together = F)
min_max <- apply(min_max, 1, function(x) paste0("[", paste(round(x, 2), collapse = ", "), "]"))

md_updated <- update_metadata(md, 
                              maps = maps, 
                              type_of_info = type_of_info,
                              mapset_from = ms_from, 
                              new_mapset = ms, 
                              variables = map_names, 
                              institution = NA,
                              description = NA, 
                              unit = NA, 
                              type_data = "raster",
                              original_range_values = min_max, 
                              year_data = NA,
                              original_pixel_res = NA, #??
                              final_pixel_res = 50, 
                              extent = "Fenoscandia",
                              primary_derived = "Derived",
                              derived_form = "???",
                              website = NA, 
                              source = NA, 
                              obtained_through = "NINA", 
                              observations = NA)
md_updated

# write updated metadata on the disk
readr::write_csv(md_updated, file = paste0("../data/spatialdb_metadata_oneimpact_",
                                           gsub("-", "", lubridate::today()),
                                           ".csv"))
# put the old metadata file in archive
# system(paste("mv", md_file, "../data/old_metadata"))
```

### Digestible biomass

```{r copy_landscape_digbiomass}
# go into mapset
ms <- "p_sam_landscape"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "landscape"

#---
# Digestible biomass
ms_from <- "u_bram.van.moorter"
maps <- execGRASS("g.list", type = "raster", mapset = ms_from, intern = T) %>% 
  grep(pattern = "digest", value = T)

# copy
for(i in maps) {
  map_in <- paste0(i, "@", ms_from)
  map_out <- i
  execGRASS("g.region", raster = map_in)
  execGRASS("g.copy", raster=paste0(map_in, ",", map_out), flags = c("overwrite"))
}

# document
md_file <- list.files("../data/", pattern = "spatialdb_metadata_oneimpact", full.names = T)
md <- readr::read_csv(md_file)

maps
map_names <- c("Digestible biomass in summer", "Digestible biomass in winter")

# get min and max from GRASS maps
min_max <- get_univar(maps, vars = c("min", "max"), all_together = F)
min_max <- apply(min_max, 1, function(x) paste0("[", paste(round(x, 1), collapse = ", "), "]"))

md_updated <- update_metadata(md, 
                              maps = maps, 
                              type_of_info = type_of_info,
                              mapset_from = ms_from, 
                              new_mapset = ms, 
                              variables = map_names, 
                              institution = NA,
                              description = NA, 
                              unit = NA, 
                              type_data = "raster",
                              original_range_values = min_max, 
                              year_data = NA,
                              original_pixel_res = NA, #??
                              final_pixel_res = 100, 
                              extent = "Norway",
                              primary_derived = "Derived",
                              derived_form = "???",
                              website = NA, 
                              source = NA, 
                              obtained_through = "NINA", 
                              observations = NA)
md_updated

# write updated metadata on the disk
readr::write_csv(md_updated, file = paste0("../data/spatialdb_metadata_oneimpact_",
                                           gsub("-", "", lubridate::today()),
                                           ".csv"))
# put the old metadata file in archive
# system(paste("mv", md_file, "../data/old_metadata"))
```

## Data from Sweden

Here we load the landscape datasets from Sweden into GRASS GIS.

### Land use NMD, SMD, and Lichen model

```{r landscape_sweden}
# go into mapset
ms <- "p_sam_landscape"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "landscape"

#---
# folder
landscape_dir = paste0(sw_dir, "03_raster/sam_landscape/")

# load vegetation data - NMD
execGRASS("r.import", input = paste0(landscape_dir, "landcover_nmd_ungeneralized/nmd2018bas_ogeneraliserad_v1_0.tif"), 
    output = "landcover_sw_nmd1_ungeneralized_10m_2018")

# load auxiliary vegetation data - SMD
execGRASS("r.import", input = paste0(landscape_dir, "landcover_smd_generalized_2013/mosaic/smdb99.tif"), 
    output = "landcover_sw_smd_25m_2004")

# elevation, aspect, slope, tpi, 10m resampled from 2m - should I add?

# load general lichen map for Sweden - Sven
execGRASS("r.import", input = paste0(landscape_dir, "lichen_sven/lav_model_south_no_roads_masked.tif"),
    output = "lichen_model_sw", flags = "overwrite")

# update metadata

# read metadata from Swedish metadata
md_sw <- readr::read_csv("../data/spatialdb_metadata_sweden_20211101.csv")[1:19]
# read new metadata file
md_file <- list.files("../data/", pattern = "spatialdb_metadata_oneimpact", full.names = T)
md <- readr::read_csv(md_file)

# pattern to search in the Swedish db
patt <- c("ungeneralized", "smd_25m", "lichen_Sweden")

# find which lines correspond to these maps in the original sweden db
ind <- purrr::map_int(patt, ~ grep(., md_sw$`Layer name`))

# final map names  
maps <- c("landcover_sw_nmd1_ungeneralized_10m_2018", "landcover_sw_smd_25m_2004",
          "lichen_model_sw")

md_updated <- update_metadata_existing(md, maps = maps, indexes = ind, existing_metadata = md_sw)
md_updated

# write updated metadata on the disk
readr::write_csv(md_updated, file = paste0("../data/spatialdb_metadata_oneimpact_",
                                           gsub("-", "", lubridate::today()),
                                           ".csv"))
# put the old metadata file in archive
# system(paste("mv", md_file, "../data/old_metadata"))
```

We still need to process some data - doing operations like resampling for a single same resolution, mosaicing maps, calculating densities etc..



# Load climate and phenology data

Now we import climate and phenology related data.

## Data from Norway

Here we'll copy the datasets from Norway that have already been in use in the previous projects (e.g. Renewable Reindeer, Prodchange).

### Climate PCAs from Norway

```{r}
# go into mapset
ms <- "p_sam_climate_phenology"
execGRASS("g.mapset", mapset = ms)

#---
# settings
type_of_info <- "climate_phenology"

#---
# PCAs 1 and 2
ms_from1 <- "g_BiogeographicalRegions_Norway_PCA_klima"
maps1 <- execGRASS("g.list", type = "raster", mapset = ms_from1, intern = T) 

# PCAs 3 and 4
ms_from2 <- "u_bram.van.moorter"
maps2 <- execGRASS("g.list", type = "raster", mapset = ms_from2, intern = T) %>% 
  grep(pattern = "klima", value = T)

ms_from <- c(rep(ms_from1, 2), rep(ms_from2, 2))
maps <- c(maps1, maps2)

# copy
for(i in 1:length(maps)) {
  map_in <- paste0(maps[i], "@", ms_from[i])
  map_out <- maps[i]
  execGRASS("g.region", raster = map_in)
  execGRASS("g.copy", raster=paste0(map_in, ",", map_out), flags = c("overwrite"))
}

# document
md_file <- list.files("../data/", pattern = "spatialdb_metadata_oneimpact", full.names = T)
md <- readr::read_csv(md_file)

maps
map_names <- paste0("Norway climatic PCA", 1:4)

# get min and max from GRASS maps
min_max <- get_univar(maps, vars = c("min", "max"), all_together = F)
min_max <- apply(min_max, 1, function(x) paste0("[", paste(round(x, 4), collapse = ", "), "]"))

# description
desc <- paste("PCA axes from climatic variables for Norway, from Bakkestuen, V., Erikstad, L., and Halvorsen, R. (2008).
Step-less models for regional environmental variation in Norway. Journal of biogeography, 35(10):1906â€“1922.")
derived_fr <- paste("Fifty-four climatic, topographical, hydrological and geological. See Bakkestuen et al. (2008) for
details")

md_updated <- update_metadata(md, 
                              maps = maps, 
                              type_of_info = type_of_info,
                              mapset_from = ms_from, 
                              new_mapset = ms, 
                              variables = map_names, 
                              institution = NA,
                              description = desc, 
                              unit = NA, 
                              type_data = "raster",
                              original_range_values = min_max, 
                              year_data = NA,
                              original_pixel_res = 1000, #??
                              final_pixel_res = 100, 
                              extent = "Norway",
                              primary_derived = "Derived",
                              derived_form = derived_fr,
                              website = NA, 
                              source = NA, 
                              obtained_through = "NINA", 
                              observations = NA)
md_updated

# write updated metadata on the disk
readr::write_csv(md_updated, file = paste0("../data/spatialdb_metadata_oneimpact_",
                                           gsub("-", "", lubridate::today()),
                                           ".csv"))
# put the old metadata file in archive
# system(paste("mv", md_file, "../data/old_metadata"))
```

## Data from Sweden

Here we load the landscape datasets from Sweden into GRASS GIS.

### Predators?

```{r}
# go into mapset
execGRASS("g.mapset", parameters = list(mapset = "p_sam_species"))

# folder with raw data
species_dir <- paste0(sw_dir, "03_raster/p_sam_species/")

# list maps in folder
files <- list.files(species_dir, pattern = "tif$", full.names = T)

test <- terra::rast(files[1])
plot(test)

# load predators data into GRASS
for(i in file) {
  
  # prepare input name
  name <- strsplit(i, "/", fixed = T)[[1]] %>% 
    dplyr::last() %>% 
    gsub(pattern = ".tif", replacement = "")
  # execGRASS("r.in.gdal", parameters = list(input = i, output = name), flags = c("overwrite"))
  
  execGRASS("r.import", parameters = list(input = i, output = name), flags = c("overwrite"))
}
    
# document

```



# Load species data

Now we import species/biotic related data.

## Data from Norway

Here we'll copy the datasets from Norway that have already been in use in the previous projects (e.g. Renewable Reindeer, Prodchange).
